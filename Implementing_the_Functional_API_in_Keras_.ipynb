{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOG+qCkETXUQZyzy2UXj6O8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shyamsai456/Deep_learning_problems/blob/main/Implementing_the_Functional_API_in_Keras_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><strong>Implementing the Functional API in Keras </h1>"
      ],
      "metadata": {
        "id": "9j3Nsz50Jk1x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VCDvB_n9G3t7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='tensorflow')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "`!pip install tensorflow==2.17.1` installs the specified version of TensorFlow.\n",
        "\n",
        " `tensorflow` is the main library for machine learning in Python.\n",
        "\n",
        " `Model` is used to create a model with the Functional API.\n",
        "\n",
        " `Input` and `Dense` are types of layers that you will use in your model.\n",
        "\n",
        "\n",
        "**Step 2: Define the Input Layer**\n",
        "\n",
        "You will define the input shape for your model. For simplicity, let's assume you are working with a dataset where each input is a vector of length 20.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "etJEegIBHdeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = Input(shape=(20,))\n",
        "print(input_layer)"
      ],
      "metadata": {
        "id": "YfbPZDSBHLVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "`Input(shape=(20,))` creates an input layer that expects input vectors of length 20.\n",
        "\n",
        "`print(input_layer)` shows the layer information, helping you understand the type of information you can get about the layers.\n",
        "\n",
        "**Step 3: Add Hidden Layers**\n",
        "\n",
        "Next, you will add a couple of hidden layers to your model. Hidden layers help the model learn complex patterns in the data.\n"
      ],
      "metadata": {
        "id": "y6VibBkpHo6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_layer1 = Dense(64, activation='relu')(input_layer)\n",
        "hidden_layer2 = Dense(64, activation='relu')(hidden_layer1)"
      ],
      "metadata": {
        "id": "J5KDYhcIHuaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "`Dense(64, activation='relu')` creates a dense (fully connected) layer with 64 units and ReLU activation function.\n",
        "\n",
        "Each hidden layer takes the output of the previous layer as its input.\n",
        "\n",
        "**Step 4: Define the Output Layer**\n",
        "\n",
        "Finally, you will define the output layer. Suppose you are working on a binary classification problem, so the output layer will have one unit with a sigmoid activation function.\n"
      ],
      "metadata": {
        "id": "7gzrH9MGHzd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_layer = Dense(1, activation='sigmoid')(hidden_layer2)"
      ],
      "metadata": {
        "id": "ES3UfttbH4ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "`Dense(1, activation='sigmoid')` creates a dense layer with 1 unit and a sigmoid activation function, suitable for binary classification.\n",
        "\n",
        "**Step 5: Create the Model**\n",
        "\n",
        "Now, you will create the model by specifying the input and output layers.\n"
      ],
      "metadata": {
        "id": "r1sgHYjtIAAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "AOjQys8IIDLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "`Model(inputs=input_layer, outputs=output_layer)` creates a Keras model that connects the input layer to the output layer through the hidden layers.\n",
        "\n",
        "`model.summary()` provides a summary of the model, showing the layers, their shapes, and the number of parameters. This helps you interpret the model architecture.\n"
      ],
      "metadata": {
        "id": "D_6CwBdEIGWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Compile the Model**\n",
        "\n",
        "Before training the model, you need to compile it. You will specify the loss function, optimizer, and evaluation metrics.\n"
      ],
      "metadata": {
        "id": "_1W_LzfLIOk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YkGR6VJyIKcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "`optimizer='adam'` specifies the Adam optimizer, a popular choice for training neural networks.\n",
        "\n",
        "`loss='binary_crossentropy'` specifies the loss function for binary classification problems.\n",
        "\n",
        "`metrics=['accuracy']` instructs Keras to evaluate the model using accuracy during training.\n",
        "\n",
        "**Step 7: Train the Model**\n",
        "\n",
        "You can now train the model using training data. For this example, let's assume `X_train` is your training input data and `y_train` is the corresponding label.\n"
      ],
      "metadata": {
        "id": "PafU-IV6IVU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example data (in practice, use real dataset)\n",
        "\n",
        "import numpy as np\n",
        "X_train = np.random.rand(1000, 20)\n",
        "y_train = np.random.randint(2, size=(1000, 1))\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "zC3zBhFyIR52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "`X_train` and `y_train` are placeholders for your actual training data.\n",
        "\n",
        "`model.fit` trains the model for a specified number of epochs and batch size.\n",
        "\n",
        "**Step 8: Evaluate the Model**\n",
        "\n",
        "After training, you can evaluate the model on test data to see how well it performs.\n"
      ],
      "metadata": {
        "id": "KJJsy90AIZml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example test data (in practice, use real dataset)\n",
        "\n",
        "X_test = np.random.rand(200, 20)\n",
        "y_test = np.random.randint(2, size=(200, 1))\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test loss: {loss}')\n",
        "print(f'Test accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "ELEQr731Idnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "`model.evaluate` computes the loss and accuracy of the model on test data.\n",
        "\n",
        "`X_test` and `y_test` are placeholders for your actual test data.\n"
      ],
      "metadata": {
        "id": "cApXlgQOIgjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropout and Batch Normalization\n",
        "\n",
        "Before we proceed with the practice exercise, let's briefly discuss two important techniques often used to improve the performance of neural networks: **Dropout Layers** and **Batch Normalization**.\n",
        "\n",
        "#### Dropout Layers\n",
        "\n",
        "Dropout is a regularization technique that helps prevent overfitting in neural networks. During training, Dropout randomly sets a fraction of input units to zero at each update cycle. This prevents the model from becoming overly reliant on any specific neurons, which encourages the network to learn more robust features that generalize better to unseen data.\n",
        "\n",
        "**Key points:**\n",
        "- Dropout is only applied during training, not during inference.\n",
        "- The dropout rate is a hyperparameter that determines the fraction of neurons to drop.\n",
        "\n",
        "\n",
        "#### Batch Normalization\n",
        "\n",
        "Batch Normalization is a technique used to improve the training stability and speed of neural networks. It normalizes the output of a previous layer by re-centering and re-scaling the data, which helps in stabilizing the learning process. By reducing the internal covariate shift (the changes in the distribution of layer inputs), batch normalization allows the model to use higher learning rates, which often speeds up convergence.\n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "- Batch normalization works by normalizing the inputs to each layer to have a mean of zero and a variance of one.\n",
        "- It is applied during both training and inference, although its behavior varies slightly between the two phases.\n",
        "- Batch normalization layers also introduce two learnable parameters that allow the model to scale and - shift the normalized output, which helps in restoring the model's representational power.\n"
      ],
      "metadata": {
        "id": "ToO6vE8VIk07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example of adding a Dropout layer in Keras:**"
      ],
      "metadata": {
        "id": "wMUBf6guIn86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=(20,))\n",
        "\n",
        "# Add a hidden layer\n",
        "hidden_layer = Dense(64, activation='relu')(input_layer)\n",
        "\n",
        "# Add a Dropout layer\n",
        "dropout_layer = Dropout(rate=0.5)(hidden_layer)\n",
        "\n",
        "# Add another hidden layer after Dropout\n",
        "hidden_layer2 = Dense(64, activation='relu')(dropout_layer)\n",
        "\n",
        "# Define the output layer\n",
        "output_layer = Dense(1, activation='sigmoid')(hidden_layer2)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "B7vbvPnhIrKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example of adding Batch Normalization in Keras:**\n"
      ],
      "metadata": {
        "id": "fhnV0oVpIubU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=(20,))\n",
        "\n",
        "# Add a hidden layer\n",
        "hidden_layer = Dense(64, activation='relu')(input_layer)\n",
        "\n",
        "# Add a BatchNormalization layer\n",
        "batch_norm_layer = BatchNormalization()(hidden_layer)\n",
        "\n",
        "# Add another hidden layer after BatchNormalization\n",
        "hidden_layer2 = Dense(64, activation='relu')(batch_norm_layer)\n",
        "\n",
        "# Define the output layer\n",
        "output_layer = Dense(1, activation='sigmoid')(hidden_layer2)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "6R4VR-d2Izrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating function to return the model with Dropout function and evaluating it**"
      ],
      "metadata": {
        "id": "2EQ0lHAqI2H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Write your code here\n",
        "def dropOutAfterHidden():\n",
        "    Input_layer = Input(shape=(20,))\n",
        "    hidden_layer = Dense(64, activation='relu')(Input_layer)\n",
        "    DropLayer = Dropout(rate=0.5)(hidden_layer)\n",
        "    hidden_layer2 = Dense(64, activation='relu')(DropLayer)\n",
        "    DropLayer2 = Dropout(rate=0.5)(hidden_layer2)\n",
        "    Out_putlayer = Dense(1, activation='sigmoid')(DropLayer2)\n",
        "    model = Model(inputs=Input_layer, outputs=Out_putlayer)\n",
        "    print(model.summary())\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model1 = dropOutAfterHidden()\n",
        "model1.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "loss, accuracy = model1.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "dwUN6YYHJHha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating function to return the model with  Batch Normalization,Different activation function and Dropout function and evaluating it**"
      ],
      "metadata": {
        "id": "g00hMsgjJNxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Write your code here\n",
        "def  diffActivationftn():\n",
        "    Inputlayer = Input(shape=(20,))\n",
        "    hidden_layer = Dense(64, activation='tanh')(Inputlayer)\n",
        "    Dropoutlayer = Dropout(rate=0.5)(hidden_layer)\n",
        "    batch_norm_layer = BatchNormalization()(Dropoutlayer)\n",
        "    hidden_layer2 = Dense(64, activation='tanh')(batch_norm_layer)\n",
        "    dropout_layer2 = Dropout(rate=0.5)(hidden_layer2)\n",
        "    output_layer = Dense(1,activation='sigmoid')(dropout_layer2)\n",
        "    model = Model(inputs=Inputlayer, outputs=output_layer)\n",
        "    model.summary()\n",
        "    model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = diffActivationftn()\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=32)\n",
        "loss, accuracy=model.evaluate(X_test,y_test)\n",
        "print(f'Test Loss ={loss}')\n",
        "print(f'Test Accuracy ={accuracy}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "myTRfJJxJYk1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}